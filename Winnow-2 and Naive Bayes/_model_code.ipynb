{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputes the data by calculatig the mean given a class and replacing all values in that class\n",
    "#that have a feature of \"?\" with the conditional mean. We round the mean to 0 or 1 when the data\n",
    "#is categorical\n",
    "def impute (data, categorical):\n",
    "    class_dfs = []\n",
    "    classes = np.unique(data['target'])\n",
    "    #goes through each label to calculate the conditional mean\n",
    "    for label in classes:\n",
    "        #change the \"?\" to nan so we can compute the mean skipping the nans\n",
    "        data_with_label = data[data['target']==label].replace('?', np.nan).astype('float')\n",
    "        means = data_with_label.mean(skipna=True)\n",
    "        #goes through each feature to replace empty vals with conditional means\n",
    "        #rounds the mean if the data is categorical\n",
    "        for feature in data.columns:\n",
    "            if categorical:\n",
    "                replacement_val = round(means[feature])\n",
    "            else:\n",
    "                replacement_val = means[feature]\n",
    "            data_with_label[feature] = data_with_label[feature].apply(lambda x: replacement_val if math.isnan(x) else x)\n",
    "        class_dfs.append(data_with_label)\n",
    "    return pd.concat(class_dfs).reset_index().drop(columns='index')\n",
    "\n",
    "def train_test (data, testing_size):\n",
    "    testing = data.sample(frac=testing_size)\n",
    "    training = data.drop(list(testing.index))\n",
    "    #we also want to seperate x and y for each set\n",
    "    y_training = (training['target'])#, dtype=np.int)\n",
    "    #drop target so its not considered a feature\n",
    "    x_training = training.drop(columns= 'target').values\n",
    "\n",
    "    y_testing = (testing['target'])\n",
    "    x_testing = testing.drop(columns= 'target').values\n",
    "    return (x_training, y_training, x_testing, y_testing)\n",
    "\n",
    "#one hot encodes each sample with a set vector size\n",
    "#I could have made the vector size dynamic but each dataset that required this had featurs that all had the same max val\n",
    "def one_hot (x, vector_size):\n",
    "    #round the data to bucket\n",
    "    x_rounded = x.astype(int)\n",
    "    x_one_hot = []\n",
    "    #for loop to add each feature to the one hot vector\n",
    "    for feature in x_rounded:\n",
    "        feature_vector = []\n",
    "        #goes through each feature and places the 1 in the right place, the rest are 0s\n",
    "        #this would fail for 0 so i added a special case for it\n",
    "        for feature_val in feature:\n",
    "            if feature_val ==0:\n",
    "                one_hot_feature = [1] + [0]*(vector_size-1)\n",
    "            else:\n",
    "                one_hot_feature = [0]*(feature_val-1) + [1] + [0]*(vector_size-feature_val)\n",
    "            feature_vector += one_hot_feature\n",
    "        x_one_hot.append(np.asarray(feature_vector, dtype=np.int))\n",
    "    return np.array(x_one_hot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that calculates the class frequency and conditional mean and variance for each feature\n",
    "#returns the above statistics in a dictionary\n",
    "def fit_gaussian_naive_bayes(x_train, y_train):\n",
    "    classes = np.unique(y_train)\n",
    "    class_statistics = {}\n",
    "    #goes through each class, calculates the stats and adds them to the dictionary\n",
    "    for c in classes:\n",
    "        class_statistics[c] = {}\n",
    "        training_c = x_train[c == y_train]\n",
    "        \n",
    "        class_frequency = len(training_c)/len(y_train)\n",
    "        mean = training_c.mean(axis=0)\n",
    "        variance = training_c.var(axis=0)\n",
    "        \n",
    "        class_statistics[c]['class_frequency'] = class_frequency\n",
    "        class_statistics[c]['mean'] = list(mean)\n",
    "        class_statistics[c]['variance'] = list(variance)\n",
    "    return(class_statistics)\n",
    "\n",
    "#takes in the fitted stats and the testing data, calculates the gaussian log likelihood for each class, \n",
    "#computes the posterior, and returns the class with the max posterior\n",
    "def predict_gaussian_naive_bayes(stats, x_test):\n",
    "    classes = list(stats.keys())\n",
    "    predicted = []\n",
    "    #goes through each sample in the testing data\n",
    "    for sample in x_test:\n",
    "        posteriors = []\n",
    "        #iterates through each class to calculate the posterior given the sample\n",
    "        for c in classes:\n",
    "            prior = stats[c]['class_frequency']\n",
    "            conditionals = []\n",
    "            #goes through each feature and calculates the conditional for that feature for the class\n",
    "            for index in range(0,len(sample)):\n",
    "                conditionals.append(gaussian_log_likelihood(stats, c, sample[index], index))\n",
    "            #sums all the individual conditionals logged conditionals to get the overall conditional\n",
    "            conditional = np.sum(conditionals)\n",
    "            #calculates the posterior\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        #chooses the max posterior and class and returns them\n",
    "        predicted.append((classes[np.argmax(posteriors)], max(posteriors)))\n",
    "    return predicted\n",
    "\n",
    "#returns the log likelihood for each feature given a class, using the fitted stats\n",
    "def gaussian_log_likelihood(class_stats, c, x, idx):\n",
    "    mean = class_stats[c]['mean'][idx]\n",
    "    variance = class_stats[c]['variance'][idx]\n",
    "    return np.log((np.exp(-((x-mean)**2)/(2*variance)))/(np.sqrt(2*np.pi*variance)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (Bernoulli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that calculates the class frequency and the probability of a feature given the class\n",
    "#adds this data to a dictionary\n",
    "def fit_bernoulli_naive_bayes(x_train, y_train):\n",
    "    classes = np.unique(y_train)\n",
    "    class_statistics = {}\n",
    "    #goes through each class to calculate the above stats\n",
    "    for c in classes:\n",
    "        class_statistics[c] = {}\n",
    "        training_c = x_train[c == y_train]\n",
    "        class_frequency = len(training_c)/len(y_train)\n",
    "        probability_given_class =[]\n",
    "        #goes through each feature calculating the probability of the feature given the class\n",
    "        for feature in range(0, len(training_c[0])):\n",
    "            count = (sum([item[feature] for item in training_c]))\n",
    "            probability_given_class.append(count/sum([item[feature] for item in x_train]))\n",
    "        #adds the stats to a dictionary\n",
    "        class_statistics[c]['class_frequency'] = class_frequency\n",
    "        class_statistics[c]['probability_given_class'] = probability_given_class\n",
    "    return(class_statistics)\n",
    "\n",
    "#function that takes in the fitted stats and the training samples and predicts the samples by taking the \n",
    "#argmax of the posteriors given a bernoulli distribution\n",
    "def predict_bernoulli_naive_bayes(stats, x_train):\n",
    "    classes = list(stats.keys())\n",
    "    predicted = []\n",
    "    #iterates through each sample to predict them\n",
    "    for sample in x_train:\n",
    "        posteriors = []\n",
    "        #calculates the posterior for each class\n",
    "        for c in classes:\n",
    "            prior = stats[c]['class_frequency']\n",
    "            conditionals = []\n",
    "            #goes through each feature to calculate the individual log likelihoods\n",
    "            for index in range(0,len(sample)):\n",
    "                conditionals.append(bernoulli_log_likelihood(stats, c, sample[index], index))\n",
    "            #adds up the conditionals to make the overall for the class\n",
    "            conditional = np.sum(conditionals)\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        #predicts the class by taking the argmax of the posterior list\n",
    "        predicted.append(classes[np.argmax(posteriors)])\n",
    "    return predicted\n",
    "\n",
    "#function that computes the bernoulli log likelihood of a feature given a class and its fitted stats\n",
    "def bernoulli_log_likelihood(class_stats, c, x, idx):\n",
    "    probability = class_stats[c]['probability_given_class'][idx]\n",
    "    return np.log(probability)*x + np.log(1-probability)*(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winnow-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes in training data, a threshold and a learning rate to calculate the fitted weights for each feature\n",
    "def fit_winnow2(x_train, y_train, threshold = 0.5, learning_rate = 2):\n",
    "    #initialize the weights to 1\n",
    "    weights = np.ones(len(x_train[0]))\n",
    "    y_train = np.array(y_train)\n",
    "    #goes through each sample to adjust the weights\n",
    "    for index, sample in enumerate(x_train):\n",
    "        #calculate our f(x) by multiplying each sample by its respective weight\n",
    "        fx = np.sum(np.multiply(sample, weights))\n",
    "        #if the sample is above the threshold, predict 1. If not, predict 0.\n",
    "        if fx > threshold:\n",
    "            y_predict = 1\n",
    "        else:\n",
    "            y_predict = 0\n",
    "        #if the prediction is incorrect and the prediction is 0 (actual is 1) we should promote\n",
    "        #if the prediction is incorrect and the prediction is 1 (actual is 0) we should demote\n",
    "        if y_predict!=y_train[index]:\n",
    "            if y_predict == 0:\n",
    "                weights = promote(sample, weights, learning_rate)\n",
    "            else:\n",
    "                weights = demote(sample, weights, learning_rate)\n",
    "    return weights\n",
    "\n",
    "#takes in the weights and and feature values, if the feature is 1 we promote by multiplying the weight by the learning rate\n",
    "def promote(sample, weights, learning_rate):\n",
    "    new_weights = []\n",
    "    for index, weight in enumerate(weights):\n",
    "        if sample[index] == 1:\n",
    "            new_weights.append(weight*learning_rate)\n",
    "        else:\n",
    "            new_weights.append(weight)\n",
    "    return(np.asarray(new_weights, dtype=np.float64))\n",
    "#takes in the weights and and feature values, if the feature is 1 we demote by dividing the weight by the learning rate\n",
    "def demote(sample, weights, learning_rate):\n",
    "    new_weights = []\n",
    "    for index, weight in enumerate(weights):\n",
    "        if sample[index] == 1:\n",
    "            new_weights.append(weight/learning_rate)\n",
    "        else:\n",
    "            new_weights.append(weight)\n",
    "    return(np.asarray(new_weights, dtype=np.float64))\n",
    "\n",
    "#takes in the testing data, the fitted weights and the threshold. using the fitted weights we make a prediction for each sample\n",
    "def predict_winnow2(x_test, weights, threshold):\n",
    "    predictions = []\n",
    "    for index, sample in enumerate(x_test):\n",
    "        #computes f(x) by multiplying the features of the sample by their respective fitted weights\n",
    "        fx = np.sum(np.multiply(sample, weights))\n",
    "        #if f(x) is above the threshold, return 1 and the distance from the threshold\n",
    "        #if it is below, return 0 and set the distance from the threshold to 0 because this will not be used for multiclass\n",
    "        if fx > threshold:\n",
    "            predictions.append((1, fx-threshold))\n",
    "        else:\n",
    "            predictions.append((0, 0))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing breast cancer data and removing the id column\n",
    "#\"Missing Attribute Values: Denoted by \"?\"\" so we need to impute those\n",
    "breast_cancer = pd.read_csv('breast-cancer-wisconsin.data', sep=\",\", header=None)\n",
    "breast_cancer.columns = [\"id\", \"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \"Marginal Adhesion\",\n",
    "               \"Single Epithelial Cell Size\", \"Bare Nuclei\", \"Bland Chromatin\", \"Normal Nucleoli\", \"Mitoses\", \"target\"]\n",
    "breast_cancer = breast_cancer.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our data labels 2 for benign and 4 for malignant, so let's relabel this to 0 and 1 respectively\n",
    "breast_cancer['target'] = breast_cancer['target'].replace(2, 0).replace(4, 1)\n",
    "\n",
    "#the missing attributes are numerical, so we impute the data by \n",
    "#finding the mean for that meature given the class\n",
    "breast_cancer = impute(breast_cancer, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have to split the data into 2/3 training and 1/3 testing\n",
    "breast_cancer_x_train,breast_cancer_y_train, breast_cancer_x_test, breast_cancer_y_test = train_test (breast_cancer, 1/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now what we have our training data, we can learn naive bayes\n",
    "breast_cancer_class_stats = fit_gaussian_naive_bayes(breast_cancer_x_train, breast_cancer_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now get our predictions for our testing data\n",
    "breast_cancer_naive_bayes_predicted_data = predict_gaussian_naive_bayes(breast_cancer_class_stats, breast_cancer_x_test)\n",
    "#grab only the predictions (not the metric)\n",
    "breast_cancer_naive_bayes_y_predict = [x[0] for x in breast_cancer_naive_bayes_predicted_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9613733905579399\n"
     ]
    }
   ],
   "source": [
    "#compute the accuracy\n",
    "breast_cancer_naive_bayes_results = [breast_cancer_naive_bayes_y_predict[index]==actual for index, actual in enumerate(breast_cancer_y_test)]\n",
    "print(breast_cancer_naive_bayes_results.count(True)/len(breast_cancer_naive_bayes_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we go on to winnow-2 but we need to one hot encode the x values before training\n",
    "#We know that the max of each columns is 10, so we use that as out vector size\n",
    "breast_cancer_x_train_one_hot = one_hot(breast_cancer_x_train, 10)\n",
    "breast_cancer_x_test_one_hot = one_hot(breast_cancer_x_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the winnow-2 algorithm\n",
    "breast_cancer_weights = fit_winnow2(breast_cancer_x_train_one_hot, breast_cancer_y_train,0.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the test data and extract the predictions from the prediction data\n",
    "breast_cancer_winnow_predict_data = predict_winnow2(breast_cancer_x_test_one_hot, weights, 0.5)\n",
    "breast_cancer_winnow_y_predict = [x[0] for x in breast_cancer_winnow_predict_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9484978540772532\n"
     ]
    }
   ],
   "source": [
    "#compute the accuracy\n",
    "breast_cancer_winnow_results = [breast_cancer_winnow_y_predict[index]==actual for index, actual in enumerate(breast_cancer_y_test)]\n",
    "print(breast_cancer_winnow_results.count(True)/len(breast_cancer_winnow_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing iris data\n",
    "iris = pd.read_csv('iris.data', sep=\",\", header=None)\n",
    "iris.columns = [\"sepal length in cm\", \"sepal width in cm\", \"petal length in cm\", \"petal width in cm\", \"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the iris data set has 3 labels so we must separate this into three classification problems\n",
    "iris_x_train,iris_y_train, iris_x_test, iris_y_test = train_test(iris, 1/3)\n",
    "#first classification testing for Iris-setosa\n",
    "iris_setosa_y_train = iris_y_train.replace('Iris-setosa', 1).replace('Iris-versicolor', 0).replace('Iris-virginica', 0)\n",
    "iris_setosa_y_test = iris_y_test.replace('Iris-setosa', 1).replace('Iris-versicolor', 0).replace('Iris-virginica', 0)\n",
    "iris_setosa_class_stats = fit_gaussian_naive_bayes(iris_x_train, iris_setosa_y_train)\n",
    "iris_setosa_naive_bayes_predicted_data = predict_gaussian_naive_bayes(iris_setosa_class_stats, iris_x_test)\n",
    "\n",
    "#second classification testing for Iris-versicolor\n",
    "iris_versicolor_y_train = iris_y_train.replace('Iris-setosa', 0).replace('Iris-versicolor', 1).replace('Iris-virginica', 0)\n",
    "iris_versicolor_y_test = iris_y_test.replace('Iris-setosa', 0).replace('Iris-versicolor', 1).replace('Iris-virginica', 0)\n",
    "iris_versicolor_class_stats = fit_gaussian_naive_bayes(iris_x_train, iris_versicolor_y_train)\n",
    "iris_versicolor_naive_bayes_predicted_data = predict_gaussian_naive_bayes(iris_versicolor_class_stats, iris_x_test)\n",
    "\n",
    "#third classification testing for Iris-virginica\n",
    "iris_virginica_y_train = iris_y_train.replace('Iris-setosa', 0).replace('Iris-versicolor', 0).replace('Iris-virginica', 1)\n",
    "iris_virginica_y_test = iris_y_test.replace('Iris-setosa', 0).replace('Iris-versicolor', 0).replace('Iris-virginica', 1)\n",
    "iris_virginica_class_stats = fit_gaussian_naive_bayes(iris_x_train, iris_virginica_y_train)\n",
    "iris_virginica_naive_bayes_predicted_data = predict_gaussian_naive_bayes(iris_virginica_class_stats, iris_x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "#using the multi-class binary classification approach\n",
    "iris_naive_bayes_y_predict = []\n",
    "#using the prediction data, we label the sample with the class that has the highest posterior\n",
    "for index in range(0, len(iris_virginica_naive_bayes_predicted_data)):\n",
    "    posteriors = [iris_setosa_naive_bayes_predicted_data[index][1], iris_versicolor_naive_bayes_predicted_data[index][1], iris_virginica_naive_bayes_predicted_data[index][1]]\n",
    "    iris_naive_bayes_y_predict.append(np.argmax(posteriors))\n",
    "\n",
    "#compute the accuracy\n",
    "iris_y_test_number_values = iris_y_test.replace('Iris-setosa', 0).replace('Iris-versicolor', 1).replace('Iris-virginica', 2)\n",
    "iris_naive_bayes_results = [iris_naive_bayes_y_predict[index]==actual for index, actual in enumerate(iris_y_test_number_values)]\n",
    "print(iris_naive_bayes_results.count(True)/len(iris_naive_bayes_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using multiclass\n",
    "iris_y_train_multi = iris_y_train.replace('Iris-setosa', 0).replace('Iris-versicolor', 1).replace('Iris-virginica', 2)\n",
    "iris_y_test_multi = iris_y_test.replace('Iris-setosa', 0).replace('Iris-versicolor', 1).replace('Iris-virginica', 2)\n",
    "iris_class_stats = fit_gaussian_naive_bayes(iris_x_train, iris_y_train_multi)\n",
    "iris_naive_bayes_predicted_data = predict_gaussian_naive_bayes(iris_class_stats, iris_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n"
     ]
    }
   ],
   "source": [
    "#using multi-class classification\n",
    "iris_naive_bayes_y_predict = [x[0] for x in iris_naive_bayes_predicted_data]\n",
    "\n",
    "iris_naive_bayes_results_multi = [iris_naive_bayes_y_predict[index]==actual for index, actual in enumerate(iris_y_test_multi)]\n",
    "print(iris_naive_bayes_results_multi.count(True)/len(iris_naive_bayes_results_multi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we go on to winnow-2 but we need to one hot encode the x values before training\n",
    "#We know that the max of each columns is 8, so we use that as out vector size\n",
    "iris_x_train_one_hot = one_hot(iris_x_train, 8)\n",
    "iris_x_test_one_hot = one_hot(iris_x_test, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n"
     ]
    }
   ],
   "source": [
    "#we already have our y values ready so we can begin to train\n",
    "#iris setosa\n",
    "iris_setosa_weights = fit_winnow2(iris_x_train_one_hot, iris_setosa_y_train,0.5,2)\n",
    "iris_setosa_winnow_predict_data = predict_winnow2(iris_x_test_one_hot, iris_setosa_weights, 0.5)\n",
    "\n",
    "#iris versicolor\n",
    "iris_versicolor_weights = fit_winnow2(iris_x_train_one_hot, iris_versicolor_y_train,0.5,2)\n",
    "iris_versicolor_winnow_predict_data = predict_winnow2(iris_x_test_one_hot, iris_versicolor_weights, 0.5)\n",
    "\n",
    "#iris virginica\n",
    "iris_virginica_weights = fit_winnow2(iris_x_train_one_hot, iris_virginica_y_train,0.5,2)\n",
    "iris_virginica_winnow_predict_data = predict_winnow2(iris_x_test_one_hot, iris_virginica_weights, 0.5)\n",
    "\n",
    "iris_winnow_y_predict = []\n",
    "#using the prediction data, we label the sample with the class that has the furthest distance from the threshold\n",
    "for index in range(0, len(iris_setosa_winnow_predict_data)):\n",
    "    posteriors = [iris_setosa_winnow_predict_data[index][1], iris_versicolor_winnow_predict_data[index][1], iris_virginica_winnow_predict_data[index][1]]\n",
    "    iris_winnow_y_predict.append(np.argmax(posteriors))\n",
    "\n",
    "#compute the accuracy\n",
    "iris_winnow_results = [iris_winnow_y_predict[index]==actual for index, actual in enumerate(iris_y_test_number_values)]\n",
    "print(iris_winnow_results.count(True)/len(iris_winnow_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing house vote data\n",
    "#Missing Attribute Values: Denoted by \"?\"\n",
    "house_vote = pd.read_csv('house-votes-84.data', sep=\",\", header=None)\n",
    "house_vote.columns = [\"target\", \"handicapped-infants\", \"water-project-cost-sharing\", \"adoption-of-the-budget-resolution\", \"physician-fee-freeze\",\n",
    "               \"el-salvador-aid\", \"religious-groups-in-schools\", \"anti-satellite-test-ban\", \"aid-to-nicaraguan-contras\", \"mx-missile\", \"immigration\",\n",
    "               \"synfuels-corporation-cutback\", \"education-spending\", \"superfund-right-to-sue\", \"crime\", \"duty-free-exports\", \"export-administration-act-south-africa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our labels are democrat and republican, so let's relabel them to 0 and 1 respectively\n",
    "house_vote['target'] = house_vote['target'].replace('democrat', 0).replace('republican', 1)\n",
    "\n",
    "#labels are represented as \"y\" or \"n\", so we change this to \"1\" and \"0\" respectively\n",
    "house_vote = house_vote.replace(\"y\", 1).replace(\"n\", 0)\n",
    "#we also have some \"?\" for missing data. Given that this data is categorical, let's take the mean given the class and round it to 0 or 1 for imputation\n",
    "house_vote = impute(house_vote, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing\n",
    "house_vote_x_train,house_vote_y_train, house_vote_x_test, house_vote_y_test = train_test(house_vote, 1/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the stats using bernoulli thisw time because our data is categorical with 0 and 1 vals\n",
    "class_stats = fit_bernoulli_naive_bayes(house_vote_x_train, house_vote_y_train)\n",
    "#use the bernoulli prediction\n",
    "y_predict = predict_bernoulli_naive_bayes(class_stats, house_vote_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "#compute the accuracy\n",
    "iris_winnow_results = [y_predict[index]==actual for index, actual in enumerate(house_vote_y_test)]\n",
    "print(iris_winnow_results.count(True)/len(iris_winnow_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8206896551724138\n"
     ]
    }
   ],
   "source": [
    "#no more preprocessing for winnow this time because the data is categorical with 0 and 1 data \n",
    "house_vote_weights = fit_winnow2(house_vote_x_train, house_vote_y_train,0.5,2)\n",
    "house_vote_winnow_predict_data = predict_winnow2(house_vote_x_test, house_vote_weights, 0.5)\n",
    "house_vote_winnow_y_predict = [x[0] for x in house_vote_winnow_predict_data]\n",
    "#compute the accuracy\n",
    "house_vote_winnow_results = [house_vote_winnow_y_predict[index]==actual for index, actual in enumerate(house_vote_y_test)]\n",
    "print(house_vote_winnow_results.count(True)/len(house_vote_winnow_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump Thickness                2.956332\n",
       "Uniformity of Cell Size        1.325328\n",
       "Uniformity of Cell Shape       1.443231\n",
       "Marginal Adhesion              1.364629\n",
       "Single Epithelial Cell Size    2.120087\n",
       "Bare Nuclei                    1.346847\n",
       "Bland Chromatin                2.100437\n",
       "Normal Nucleoli                1.290393\n",
       "Mitoses                        1.063319\n",
       "target                         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer[breast_cancer['target']==0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump Thickness                7.195021\n",
       "Uniformity of Cell Size        6.572614\n",
       "Uniformity of Cell Shape       6.560166\n",
       "Marginal Adhesion              5.547718\n",
       "Single Epithelial Cell Size    5.298755\n",
       "Bare Nuclei                    7.627615\n",
       "Bland Chromatin                5.979253\n",
       "Normal Nucleoli                5.863071\n",
       "Mitoses                        2.589212\n",
       "target                         1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer[breast_cancer['target']==1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
